# ğŸš€ æ··åˆæª¢ç´¢ RAG ç³»çµ±å®Œæ•´æ•™å­¸æ–‡ä»¶

## ğŸ“‹ ç›®éŒ„
1. [ç³»çµ±ç°¡ä»‹](#ç³»çµ±ç°¡ä»‹)
2. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
3. [ç³»çµ±æ¶æ§‹](#ç³»çµ±æ¶æ§‹)
4. [å®‰è£èˆ‡è¨­å®š](#å®‰è£èˆ‡è¨­å®š)
5. [ç¨‹å¼ç¢¼è©³è§£](#ç¨‹å¼ç¢¼è©³è§£)
6. [ä½¿ç”¨ç¯„ä¾‹](#ä½¿ç”¨ç¯„ä¾‹)
7. [æ•ˆèƒ½å„ªåŒ–](#æ•ˆèƒ½å„ªåŒ–)
8. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## ğŸ¯ ç³»çµ±ç°¡ä»‹

### ä»€éº¼æ˜¯æ··åˆæª¢ç´¢ RAGï¼Ÿ

æ··åˆæª¢ç´¢ RAGï¼ˆHybrid Retrieval RAGï¼‰çµåˆäº†å…©ç¨®æª¢ç´¢æŠ€è¡“çš„å„ªå‹¢ï¼š

1. **å‘é‡æª¢ç´¢ï¼ˆVector Searchï¼‰**ï¼šæ•æ‰èªç¾©ç›¸ä¼¼æ€§
2. **é—œéµå­—æª¢ç´¢ï¼ˆKeyword Searchï¼‰**ï¼šç²¾ç¢ºåŒ¹é…é‡è¦è©å½™

### ç‚ºä»€éº¼éœ€è¦æ··åˆæª¢ç´¢ï¼Ÿ

| æª¢ç´¢æ–¹å¼ | å„ªé» | ç¼ºé» |
|---------|------|------|
| **ç´”å‘é‡æª¢ç´¢** | âœ… ç†è§£èªç¾©<br>âœ… è™•ç†åŒç¾©è©<br>âœ… è·¨èªè¨€æª¢ç´¢ | âŒ å¯èƒ½å¿½ç•¥ç²¾ç¢ºåŒ¹é…<br>âŒ å°å°ˆæœ‰åè©æ•ˆæœå·®<br>âŒ è¨ˆç®—æˆæœ¬é«˜ |
| **ç´”é—œéµå­—æª¢ç´¢** | âœ… ç²¾ç¢ºåŒ¹é…<br>âœ… é€Ÿåº¦å¿«<br>âœ… å¯è§£é‡‹æ€§å¼· | âŒ ç„¡æ³•ç†è§£èªç¾©<br>âŒ ç„¡æ³•è™•ç†åŒç¾©è©<br>âŒ ä¾è³´åˆ†è©å“è³ª |
| **æ··åˆæª¢ç´¢** | âœ… çµåˆå…©è€…å„ªé»<br>âœ… æ›´é«˜çš„å¬å›ç‡<br>âœ… æ›´å¥½çš„æ’åº | âŒ å¯¦ä½œè¤‡é›œ<br>âŒ éœ€è¦èª¿æ•´æ¬Šé‡ |

### å¯¦éš›æ‡‰ç”¨å ´æ™¯

```python
# ç¯„ä¾‹ï¼šä¸åŒæŸ¥è©¢çš„æœ€ä½³æª¢ç´¢æ–¹å¼

# 1. é©åˆå‘é‡æª¢ç´¢çš„æŸ¥è©¢
query1 = "å¦‚ä½•æå‡ç¨‹å¼åŸ·è¡Œæ•ˆç‡"  # èªç¾©æŸ¥è©¢

# 2. é©åˆé—œéµå­—æª¢ç´¢çš„æŸ¥è©¢
query2 = "Python 3.11 asyncio"  # ç²¾ç¢ºæŠ€è¡“è¡“èª

# 3. éœ€è¦æ··åˆæª¢ç´¢çš„æŸ¥è©¢
query3 = "FAISS å¦‚ä½•åŠ é€Ÿç›¸ä¼¼åº¦æœå°‹"  # æ—¢æœ‰å°ˆæœ‰åè©åˆæœ‰èªç¾©
```

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### 1. FAISSï¼ˆFacebook AI Similarity Searchï¼‰

#### ä»€éº¼æ˜¯ FAISSï¼Ÿ

FAISS æ˜¯ Facebook é–‹ç™¼çš„å‘é‡ç›¸ä¼¼åº¦æœå°‹åº«ï¼Œå°ˆé–€å„ªåŒ–å¤§è¦æ¨¡å‘é‡æª¢ç´¢ã€‚

#### FAISS ç´¢å¼•é¡å‹

```python
# 1. Flat Indexï¼ˆç²¾ç¢ºæœå°‹ï¼‰
index_flat = faiss.IndexFlatIP(dimension)
# å„ªé»ï¼š100% ç²¾ç¢º
# ç¼ºé»ï¼šé€Ÿåº¦æ…¢ O(n)
# é©ç”¨ï¼š< 10è¬å‘é‡

# 2. IVF Indexï¼ˆå€’æ’ç´¢å¼•ï¼‰
quantizer = faiss.IndexFlatIP(dimension)
index_ivf = faiss.IndexIVFFlat(quantizer, dimension, n_clusters)
# å„ªé»ï¼šé€Ÿåº¦å¿«
# ç¼ºé»ï¼šéœ€è¦è¨“ç·´ï¼Œç²¾åº¦ç•¥ä½
# é©ç”¨ï¼š10è¬-1000è¬å‘é‡

# 3. HNSW Indexï¼ˆåˆ†å±¤å°èˆªå°ä¸–ç•Œï¼‰
index_hnsw = faiss.IndexHNSWFlat(dimension, M=32)
# å„ªé»ï¼šæ¥µå¿«çš„æŸ¥è©¢é€Ÿåº¦
# ç¼ºé»ï¼šè¨˜æ†¶é«”æ¶ˆè€—å¤§
# é©ç”¨ï¼šéœ€è¦å³æ™‚æŸ¥è©¢çš„å ´æ™¯
```

#### ç›¸ä¼¼åº¦è¨ˆç®—

```python
# é¤˜å¼¦ç›¸ä¼¼åº¦ï¼ˆæœ€å¸¸ç”¨ï¼‰
# æ­¥é©Ÿï¼š1. æ­£è¦åŒ–å‘é‡ 2. è¨ˆç®—å…§ç©
faiss.normalize_L2(vectors)  # æ­£è¦åŒ–
similarity = np.dot(vec1, vec2)  # å…§ç© = é¤˜å¼¦ç›¸ä¼¼åº¦

# æ­æ°è·é›¢
distance = np.linalg.norm(vec1 - vec2)

# å…§ç©ï¼ˆç”¨æ–¼æ­£è¦åŒ–å¾Œçš„å‘é‡ï¼‰
similarity = np.dot(vec1, vec2)
```

### 2. BM25ï¼ˆBest Matching 25ï¼‰

#### BM25 å…¬å¼è§£æ

```
Score(Q, D) = Î£ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))

å…¶ä¸­ï¼š
- Q: æŸ¥è©¢
- D: æ–‡æª”
- qi: æŸ¥è©¢ä¸­çš„ç¬¬ i å€‹è©
- f(qi, D): è© qi åœ¨æ–‡æª” D ä¸­çš„é »ç‡
- |D|: æ–‡æª” D çš„é•·åº¦
- avgdl: å¹³å‡æ–‡æª”é•·åº¦
- k1, b: å¯èª¿åƒæ•¸
```

#### BM25 åƒæ•¸èªªæ˜

```python
class BM25:
    def __init__(self, k1=1.5, b=0.75):
        """
        k1: è©é »é£½å’Œåƒæ•¸
            - è¼ƒå°å€¼(0.5-1.2): è©é »å¿«é€Ÿé£½å’Œ
            - è¼ƒå¤§å€¼(2.0-3.0): è©é »ç·©æ…¢é£½å’Œ
            - é è¨­ 1.5: å¹³è¡¡é¸æ“‡

        b: æ–‡æª”é•·åº¦æ­¸ä¸€åŒ–åƒæ•¸
            - 0: ä¸è€ƒæ…®æ–‡æª”é•·åº¦
            - 1: å®Œå…¨æ­¸ä¸€åŒ–
            - é è¨­ 0.75: éƒ¨åˆ†æ­¸ä¸€åŒ–
        """
```

#### BM25 vs TF-IDF

```python
# TF-IDF å•é¡Œï¼šè©é »ç·šæ€§å¢é•·
# å¦‚æœ "Python" å‡ºç¾ 100 æ¬¡ï¼Œæ¬Šé‡æ˜¯å‡ºç¾ 1 æ¬¡çš„ 100 å€

# BM25 è§£æ±ºï¼šè©é »é£½å’Œ
# "Python" å‡ºç¾ 100 æ¬¡çš„æ¬Šé‡åªæ˜¯ 1 æ¬¡çš„ç´„ 3-4 å€

import matplotlib.pyplot as plt
import numpy as np

# è¦–è¦ºåŒ–è©é »é£½å’Œæ•ˆæœ
tf = np.arange(0, 20)
tfidf_score = tf  # ç·šæ€§å¢é•·
bm25_score = (tf * 2.5) / (tf + 1.5)  # é£½å’Œå¢é•·

plt.figure(figsize=(10, 6))
plt.plot(tf, tfidf_score, label='TF-IDF', linewidth=2)
plt.plot(tf, bm25_score, label='BM25 (k1=1.5)', linewidth=2)
plt.xlabel('è©é » (Term Frequency)')
plt.ylabel('åˆ†æ•¸')
plt.title('TF-IDF vs BM25 è©é »é£½å’Œæ•ˆæœ')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

### 3. æ··åˆæª¢ç´¢ç­–ç•¥

#### åˆ†æ•¸èåˆæ–¹æ³•

##### æ–¹æ³• 1ï¼šåŠ æ¬Šå¹³å‡ï¼ˆWeighted Averageï¼‰

```python
def weighted_fusion(vector_score, keyword_score, alpha=0.7):
    """
    ç°¡å–®åŠ æ¬Šèåˆ

    alpha: å‘é‡æª¢ç´¢æ¬Šé‡ (0-1)
    """
    return alpha * vector_score + (1 - alpha) * keyword_score
```

##### æ–¹æ³• 2ï¼šå€’æ•¸æ’åèåˆï¼ˆRRF - Reciprocal Rank Fusionï¼‰

```python
def reciprocal_rank_fusion(rankings_list, k=60):
    """
    RRF èåˆå¤šå€‹æ’ååˆ—è¡¨

    k: å¹³æ»‘åƒæ•¸ï¼Œé€šå¸¸è¨­ç‚º 60

    åŸç†ï¼šæ’åè¶Šé å‰ï¼Œè²¢ç»è¶Šå¤§
    å…¬å¼ï¼šscore = Î£ 1/(k + rank)
    """
    scores = {}

    for rankings in rankings_list:
        for rank, doc_id in enumerate(rankings, 1):
            if doc_id not in scores:
                scores[doc_id] = 0
            scores[doc_id] += 1 / (k + rank)

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

# ä½¿ç”¨ç¯„ä¾‹
vector_results = ['doc1', 'doc3', 'doc5', 'doc2']  # å‘é‡æª¢ç´¢çµæœ
keyword_results = ['doc2', 'doc1', 'doc4', 'doc6']  # BM25 çµæœ

fused = reciprocal_rank_fusion([vector_results, keyword_results])
# çµæœï¼šèåˆå¾Œçš„æ’å
```

##### æ–¹æ³• 3ï¼šå­¸ç¿’èåˆæ¬Šé‡ï¼ˆLearning to Rankï¼‰

```python
def learn_fusion_weights(training_data):
    """
    ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ–¹æ³•å­¸ç¿’æœ€ä½³æ¬Šé‡

    å¯ä»¥ä½¿ç”¨ï¼š
    - é‚è¼¯å›æ­¸
    - LambdaMART
    - ç¥ç¶“ç¶²è·¯
    """
    from sklearn.linear_model import LogisticRegression

    X = training_data[['vector_score', 'keyword_score']]
    y = training_data['relevance']  # 0 æˆ– 1

    model = LogisticRegression()
    model.fit(X, y)

    return model.coef_
```

### 4. é‡æ’åºï¼ˆRerankingï¼‰

#### ä»€éº¼æ˜¯é‡æ’åºï¼Ÿ

é‡æ’åºæ˜¯å°åˆæ­¥æª¢ç´¢çµæœé€²è¡Œç²¾ç´°æ’åºçš„éç¨‹ï¼š

```
åˆæ­¥æª¢ç´¢ï¼ˆå¿«é€Ÿï¼‰ â†’ å€™é¸æ–‡æª”ï¼ˆ100å€‹ï¼‰ â†’ é‡æ’åºï¼ˆç²¾ç¢ºï¼‰ â†’ æœ€çµ‚çµæœï¼ˆ10å€‹ï¼‰
```

#### äº¤å‰ç·¨ç¢¼å™¨ï¼ˆCross-Encoderï¼‰

```python
def cross_encoder_rerank(query, documents):
    """
    ä½¿ç”¨äº¤å‰ç·¨ç¢¼å™¨é‡æ’åº

    èˆ‡é›™ç·¨ç¢¼å™¨çš„å€åˆ¥ï¼š
    - é›™ç·¨ç¢¼å™¨ï¼šåˆ†åˆ¥ç·¨ç¢¼ query å’Œ docï¼Œè¨ˆç®—ç›¸ä¼¼åº¦
    - äº¤å‰ç·¨ç¢¼å™¨ï¼šåŒæ™‚ç·¨ç¢¼ [query, doc]ï¼Œç›´æ¥è¼¸å‡ºç›¸é—œæ€§

    å„ªé»ï¼šæ›´æº–ç¢º
    ç¼ºé»ï¼šæ›´æ…¢ï¼ˆä¸èƒ½é è¨ˆç®—ï¼‰
    """
    from sentence_transformers import CrossEncoder

    model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

    # æº–å‚™è¼¸å…¥å°
    pairs = [[query, doc] for doc in documents]

    # è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸
    scores = model.predict(pairs)

    # æ’åº
    ranked = sorted(zip(documents, scores),
                   key=lambda x: x[1],
                   reverse=True)

    return ranked
```

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç”¨æˆ¶æŸ¥è©¢                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      æŸ¥è©¢è™•ç†å™¨          â”‚
          â”‚  - åˆ†è©/Tokenization    â”‚
          â”‚  - æŸ¥è©¢æ“´å±•             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ å‘é‡ç·¨ç¢¼å™¨  â”‚  â”‚ é—œéµå­—è™•ç†  â”‚
        â”‚ (Encoder)  â”‚  â”‚  (BM25)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   FAISS    â”‚  â”‚  BM25      â”‚
        â”‚   ç´¢å¼•     â”‚  â”‚  ç´¢å¼•      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚        â”‚
                  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      åˆ†æ•¸èåˆå™¨         â”‚
          â”‚  (Score Fusion)        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      é‡æ’åºå™¨          â”‚
          â”‚   (Reranker)          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     ç”Ÿæˆå™¨ (LLM)       â”‚
          â”‚  Context + Query       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    ç­”æ¡ˆ      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è³‡æ–™æµç¨‹

```python
# 1. ç´¢å¼•å»ºç«‹éšæ®µ
documents â†’ åˆ†å¡Š â†’ ç·¨ç¢¼ â†’ å„²å­˜åˆ° FAISS + BM25

# 2. æŸ¥è©¢éšæ®µ
query â†’ ä¸¦è¡Œæª¢ç´¢ â†’ èåˆ â†’ é‡æ’åº â†’ ç”Ÿæˆç­”æ¡ˆ
```

---

## ğŸ’» å®‰è£èˆ‡è¨­å®š

### ç’°å¢ƒéœ€æ±‚

```bash
# Python ç‰ˆæœ¬
Python >= 3.8

# GPUï¼ˆå¯é¸ï¼‰
CUDA 11.x (å¦‚æœä½¿ç”¨ GPU ç‰ˆ FAISS)
```

### å®‰è£æ­¥é©Ÿ

```bash
# 1. å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv rag_env
source rag_env/bin/activate  # Linux/Mac
# æˆ–
rag_env\Scripts\activate  # Windows

# 2. å®‰è£åŸºç¤å¥—ä»¶
pip install numpy scipy

# 3. å®‰è£ FAISS
# CPU ç‰ˆæœ¬
pip install faiss-cpu

# GPU ç‰ˆæœ¬ï¼ˆéœ€è¦ CUDAï¼‰
pip install faiss-gpu

# 4. å®‰è£ BM25
pip install rank-bm25

# 5. å®‰è£å…¶ä»–ä¾è³´
pip install openai python-dotenv jieba

# 6. å®‰è£å¯é¸å¥—ä»¶ï¼ˆç”¨æ–¼é€²éšåŠŸèƒ½ï¼‰
pip install sentence-transformers  # äº¤å‰ç·¨ç¢¼å™¨
pip install matplotlib  # è¦–è¦ºåŒ–
```

### ç’°å¢ƒè®Šæ•¸è¨­å®š

```bash
# å»ºç«‹ .env æª”æ¡ˆ
touch .env

# ç·¨è¼¯ .env æª”æ¡ˆï¼ŒåŠ å…¥ API é‡‘é‘°
OPENAI_API_KEY=your_api_key_here
```

---

## ğŸ“– ç¨‹å¼ç¢¼è©³è§£

### 1. æ–‡æœ¬è™•ç†å™¨ï¼ˆTextProcessorï¼‰

```python
class TextProcessor:
    """
    æ–‡æœ¬è™•ç†å™¨ï¼šè™•ç†ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬
    """

    def __init__(self, language: str = "mixed"):
        """
        åˆå§‹åŒ–

        åƒæ•¸ï¼š
            language: èªè¨€è¨­å®š
                - "chinese": ç´”ä¸­æ–‡
                - "english": ç´”è‹±æ–‡
                - "mixed": ä¸­è‹±æ··åˆ
        """
        self.language = language

        # è¼‰å…¥åœç”¨è©
        self.stop_words = self._load_stop_words()

    def tokenize(self, text: str) -> List[str]:
        """
        åˆ†è©è™•ç†

        è™•ç†æµç¨‹ï¼š
        1. åˆ¤æ–·èªè¨€é¡å‹
        2. é¸æ“‡é©ç•¶çš„åˆ†è©å™¨
        3. éæ¿¾åœç”¨è©
        4. è¿”å›è©å½™åˆ—è¡¨
        """
        if self._is_chinese(text):
            # ä¸­æ–‡åˆ†è©
            tokens = list(jieba.cut(text))
        else:
            # è‹±æ–‡åˆ†è©
            tokens = text.lower().split()

        # éæ¿¾
        tokens = [t for t in tokens if self._is_valid_token(t)]

        return tokens

    def split_text(self, text: str, chunk_size: int = 200, overlap: int = 50):
        """
        æ™ºæ…§æ–‡æœ¬åˆ†å¡Š

        ç­–ç•¥ï¼š
        1. å„ªå…ˆåœ¨å¥å­é‚Šç•Œåˆ‡åˆ†
        2. ä¿æŒèªç¾©å®Œæ•´æ€§
        3. æ§åˆ¶å¡Šå¤§å°
        """
        sentences = self._split_sentences(text)
        chunks = []
        current_chunk = []
        current_size = 0

        for sentence in sentences:
            sentence_size = len(sentence)

            if current_size + sentence_size <= chunk_size:
                current_chunk.append(sentence)
                current_size += sentence_size
            else:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = [sentence]
                current_size = sentence_size

        if current_chunk:
            chunks.append(' '.join(current_chunk))

        return chunks
```

### 2. FAISS æª¢ç´¢å™¨è©³è§£

```python
class FAISSRetriever:
    """
    FAISS å‘é‡æª¢ç´¢å™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å»ºç«‹é«˜æ•ˆçš„å‘é‡ç´¢å¼•
    2. æ”¯æ´å¤šç¨®ç´¢å¼•é¡å‹
    3. æ‰¹é‡æ·»åŠ å’Œæœå°‹
    """

    def __init__(self, dimension: int = 1536, index_type: str = "flat"):
        self.dimension = dimension
        self.index = self._create_index(index_type)
        self.documents = []

        # æ•ˆèƒ½ç›£æ§
        self.search_time = []
        self.add_time = []

    def _create_index(self, index_type: str) -> faiss.Index:
        """
        å»ºç«‹ FAISS ç´¢å¼•

        é¸æ“‡ç­–ç•¥ï¼š
        - å°è³‡æ–™é›†ï¼ˆ<10è¬ï¼‰: Flat
        - ä¸­è³‡æ–™é›†ï¼ˆ10è¬-100è¬ï¼‰: IVF
        - å¤§è³‡æ–™é›†ï¼ˆ>100è¬ï¼‰: HNSW æˆ– IVF+PQ
        """
        if index_type == "flat":
            # ç²¾ç¢ºæœå°‹
            index = faiss.IndexFlatIP(self.dimension)

        elif index_type == "ivf":
            # IVFï¼šå…ˆèšé¡å†æœå°‹
            n_list = 100  # èšé¡ä¸­å¿ƒæ•¸
            quantizer = faiss.IndexFlatIP(self.dimension)
            index = faiss.IndexIVFFlat(
                quantizer,
                self.dimension,
                n_list,
                faiss.METRIC_INNER_PRODUCT
            )

        elif index_type == "ivfpq":
            # IVF+PQï¼šå£“ç¸®å‘é‡ä»¥ç¯€çœè¨˜æ†¶é«”
            n_list = 100
            m = 8  # å­å‘é‡æ•¸
            quantizer = faiss.IndexFlatIP(self.dimension)
            index = faiss.IndexIVFPQ(
                quantizer,
                self.dimension,
                n_list,
                m,
                8  # æ¯å€‹å­å‘é‡çš„ä½å…ƒæ•¸
            )

        elif index_type == "hnsw":
            # HNSWï¼šåœ–çµæ§‹ç´¢å¼•
            M = 32  # æ¯å€‹ç¯€é»çš„é€£æ¥æ•¸
            index = faiss.IndexHNSWFlat(
                self.dimension,
                M,
                faiss.METRIC_INNER_PRODUCT
            )
            # HNSW ç‰¹å®šåƒæ•¸
            index.hnsw.efConstruction = 40  # å»ºæ§‹æ™‚çš„æœå°‹å¯¬åº¦
            index.hnsw.efSearch = 16  # æŸ¥è©¢æ™‚çš„æœå°‹å¯¬åº¦

        return index

    def add_documents(self, embeddings: np.ndarray, documents: List[str]):
        """
        æ‰¹é‡æ·»åŠ æ–‡æª”

        å„ªåŒ–æŠ€å·§ï¼š
        1. æ‰¹é‡æ·»åŠ è€Œéé€å€‹æ·»åŠ 
        2. å‘é‡æ­£è¦åŒ–ä»¥ä½¿ç”¨å…§ç©
        3. ä½¿ç”¨ float32 ç¯€çœè¨˜æ†¶é«”
        """
        import time

        start_time = time.time()

        # ç¢ºä¿è³‡æ–™é¡å‹æ­£ç¢º
        embeddings = embeddings.astype('float32')

        # æ­£è¦åŒ–ï¼ˆé‡è¦ï¼ï¼‰
        faiss.normalize_L2(embeddings)

        # è¨“ç·´ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if hasattr(self.index, 'is_trained') and not self.index.is_trained:
            print("è¨“ç·´ç´¢å¼•...")
            self.index.train(embeddings)

        # æ·»åŠ å‘é‡
        self.index.add(embeddings)
        self.documents.extend(documents)

        add_time = time.time() - start_time
        self.add_time.append(add_time)

        print(f"æ·»åŠ  {len(documents)} å€‹æ–‡æª”ï¼Œè€—æ™‚ {add_time:.2f} ç§’")

    def search(self, query_embedding: np.ndarray, top_k: int = 5):
        """
        å‘é‡æœå°‹

        å„ªåŒ–æœå°‹ï¼š
        1. æŸ¥è©¢å‘é‡æ­£è¦åŒ–
        2. ä½¿ç”¨ nprobe åƒæ•¸ï¼ˆIVFï¼‰
        3. æ‰¹é‡æŸ¥è©¢
        """
        import time

        start_time = time.time()

        # æº–å‚™æŸ¥è©¢å‘é‡
        if query_embedding.ndim == 1:
            query_embedding = query_embedding.reshape(1, -1)

        query_embedding = query_embedding.astype('float32')
        faiss.normalize_L2(query_embedding)

        # è¨­å®šæœå°‹åƒæ•¸ï¼ˆIVF ç´¢å¼•ï¼‰
        if hasattr(self.index, 'nprobe'):
            self.index.nprobe = 10  # æœå°‹ 10 å€‹èšé¡ä¸­å¿ƒ

        # åŸ·è¡Œæœå°‹
        scores, indices = self.index.search(query_embedding, top_k)

        search_time = time.time() - start_time
        self.search_time.append(search_time)

        # è™•ç†çµæœ
        results = []
        for idx, score in zip(indices[0], scores[0]):
            if idx != -1:  # æœ‰æ•ˆç´¢å¼•
                results.append((int(idx), float(score)))

        return results

    def get_statistics(self):
        """
        ç²å–æ•ˆèƒ½çµ±è¨ˆ
        """
        import numpy as np

        stats = {
            "index_size": self.index.ntotal,
            "dimension": self.dimension,
            "avg_add_time": np.mean(self.add_time) if self.add_time else 0,
            "avg_search_time": np.mean(self.search_time) if self.search_time else 0,
        }

        return stats
```

### 3. BM25 æª¢ç´¢å™¨è©³è§£

```python
class BM25Retriever:
    """
    BM25 é—œéµå­—æª¢ç´¢å™¨

    å¯¦ä½œç´°ç¯€ï¼š
    1. æ–‡æª”é è™•ç†å’Œåˆ†è©
    2. IDF è¨ˆç®—å’Œå¿«å–
    3. é«˜æ•ˆçš„è©•åˆ†è¨ˆç®—
    """

    def __init__(self, k1: float = 1.5, b: float = 0.75):
        """
        åƒæ•¸èª¿å„ªæŒ‡å—ï¼š

        k1 (è©é »é£½å’Œåº¦):
        - çŸ­æ–‡æª”: 1.2
        - æ¨™æº–æ–‡æª”: 1.5
        - é•·æ–‡æª”: 2.0

        b (é•·åº¦æ­¸ä¸€åŒ–):
        - é•·åº¦å·®ç•°å°: 0.5
        - æ¨™æº–: 0.75
        - é•·åº¦å·®ç•°å¤§: 1.0
        """
        self.k1 = k1
        self.b = b

        # æ–‡æª”å­˜å„²
        self.corpus = []
        self.tokenized_corpus = []

        # çµ±è¨ˆè³‡è¨Š
        self.doc_len = []
        self.avgdl = 0
        self.doc_freq = {}  # æ–‡æª”é »ç‡
        self.idf = {}  # IDF å¿«å–

    def add_documents(self, documents: List[str]):
        """
        æ·»åŠ æ–‡æª”ä¸¦å»ºç«‹ç´¢å¼•
        """
        self.corpus = documents

        # åˆ†è©
        text_processor = TextProcessor()
        self.tokenized_corpus = [
            text_processor.tokenize(doc) for doc in documents
        ]

        # è¨ˆç®—æ–‡æª”é•·åº¦
        self.doc_len = [len(doc) for doc in self.tokenized_corpus]
        self.avgdl = sum(self.doc_len) / len(self.doc_len)

        # è¨ˆç®— IDF
        self._calculate_idf()

        # å»ºç«‹ BM25 ç‰©ä»¶
        from rank_bm25 import BM25Okapi
        self.bm25 = BM25Okapi(
            self.tokenized_corpus,
            k1=self.k1,
            b=self.b
        )

    def _calculate_idf(self):
        """
        è¨ˆç®— IDFï¼ˆé€†æ–‡æª”é »ç‡ï¼‰

        IDF(t) = log((N - df(t) + 0.5) / (df(t) + 0.5))

        å…¶ä¸­ï¼š
        - N: ç¸½æ–‡æª”æ•¸
        - df(t): åŒ…å«è© t çš„æ–‡æª”æ•¸
        """
        N = len(self.tokenized_corpus)

        # è¨ˆç®—æ–‡æª”é »ç‡
        for doc in self.tokenized_corpus:
            seen = set()
            for word in doc:
                if word not in seen:
                    self.doc_freq[word] = self.doc_freq.get(word, 0) + 1
                    seen.add(word)

        # è¨ˆç®— IDF
        import math
        for word, df in self.doc_freq.items():
            self.idf[word] = math.log((N - df + 0.5) / (df + 0.5))

    def search(self, query: str, top_k: int = 5):
        """
        BM25 æœå°‹

        å„ªåŒ–æŠ€å·§ï¼š
        1. æŸ¥è©¢æ“´å±•
        2. æ—©æœŸçµ‚æ­¢
        3. å¿«å–è¨ˆç®—çµæœ
        """
        if not self.bm25:
            return []

        # åˆ†è©æŸ¥è©¢
        text_processor = TextProcessor()
        tokenized_query = text_processor.tokenize(query)

        # æŸ¥è©¢æ“´å±•ï¼ˆå¯é¸ï¼‰
        expanded_query = self._expand_query(tokenized_query)

        # è¨ˆç®—åˆ†æ•¸
        scores = self.bm25.get_scores(expanded_query)

        # ç²å– top-k
        top_indices = np.argsort(scores)[::-1][:top_k]

        # éæ¿¾é›¶åˆ†
        results = [
            (int(idx), float(scores[idx]))
            for idx in top_indices
            if scores[idx] > 0
        ]

        return results

    def _expand_query(self, query_tokens: List[str]) -> List[str]:
        """
        æŸ¥è©¢æ“´å±•

        ç­–ç•¥ï¼š
        1. åŒç¾©è©æ“´å±•
        2. è©å¹¹æå–
        3. ç›¸é—œè©æ·»åŠ 
        """
        expanded = query_tokens.copy()

        # ç°¡å–®çš„åŒç¾©è©æ“´å±•ç¯„ä¾‹
        synonyms = {
            "å¿«": ["å¿«é€Ÿ", "è¿…é€Ÿ"],
            "æœå°‹": ["æª¢ç´¢", "æŸ¥è©¢", "æœç´¢"],
            "è³‡æ–™": ["æ•¸æ“š", "è³‡è¨Š"]
        }

        for token in query_tokens:
            if token in synonyms:
                expanded.extend(synonyms[token])

        return expanded
```

### 4. æ··åˆæª¢ç´¢ç³»çµ±æ ¸å¿ƒ

```python
class HybridRAGSystem:
    """
    æ··åˆæª¢ç´¢ RAG ç³»çµ±

    ç³»çµ±ç‰¹é»ï¼š
    1. é›™è·¯æª¢ç´¢
    2. æ™ºæ…§èåˆ
    3. é‡æ’åºå„ªåŒ–
    4. ç­”æ¡ˆç”Ÿæˆ
    """

    def hybrid_search(self, query: str, top_k: int = 5):
        """
        æ··åˆæª¢ç´¢æ ¸å¿ƒé‚è¼¯
        """
        # === ç¬¬ä¸€éšæ®µï¼šä¸¦è¡Œæª¢ç´¢ ===

        # 1. å‘é‡æª¢ç´¢
        query_embedding = self._get_embedding(query)
        vector_results = self.faiss_retriever.search(
            query_embedding,
            top_k=top_k * 2  # æª¢ç´¢æ›´å¤šå€™é¸
        )

        # 2. BM25 æª¢ç´¢
        keyword_results = self.bm25_retriever.search(
            query,
            top_k=top_k * 2
        )

        # === ç¬¬äºŒéšæ®µï¼šåˆ†æ•¸èåˆ ===

        # ä½¿ç”¨ RRF èåˆ
        fused_scores = self._reciprocal_rank_fusion(
            vector_results,
            keyword_results,
            vector_weight=self.vector_weight,
            keyword_weight=self.keyword_weight
        )

        # === ç¬¬ä¸‰éšæ®µï¼šçµæœè™•ç† ===

        # ç²å–æ–‡æª”å…§å®¹
        results = []
        for doc_id, score in fused_scores[:top_k]:
            idx = self._get_doc_index(doc_id)
            if idx < len(self.documents):
                doc = self.documents[idx]
                results.append((doc.content, score, doc.metadata))

        return results

    def _reciprocal_rank_fusion(self,
                                vector_results: List[Tuple[int, float]],
                                keyword_results: List[Tuple[int, float]],
                                vector_weight: float = 0.7,
                                keyword_weight: float = 0.3,
                                k: int = 60):
        """
        å€’æ•¸æ’åèåˆï¼ˆRRFï¼‰

        åŸç†ï¼š
        - æ’åè¶Šé å‰ï¼Œè²¢ç»è¶Šå¤§
        - ä½¿ç”¨å€’æ•¸å‡½æ•¸å¹³æ»‘å·®ç•°
        - k åƒæ•¸æ§åˆ¶å¹³æ»‘ç¨‹åº¦
        """
        doc_scores = {}

        # è™•ç†å‘é‡æª¢ç´¢çµæœ
        for rank, (idx, score) in enumerate(vector_results):
            doc_id = f"doc_{idx}"
            rrf_score = 1 / (k + rank + 1)
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + \
                                 vector_weight * rrf_score

        # è™•ç† BM25 çµæœ
        for rank, (idx, score) in enumerate(keyword_results):
            doc_id = f"doc_{idx}"
            rrf_score = 1 / (k + rank + 1)
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + \
                                 keyword_weight * rrf_score

        # æ’åº
        sorted_docs = sorted(
            doc_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return sorted_docs

    def rerank_with_cross_encoder(self,
                                  query: str,
                                  documents: List[str],
                                  top_k: int = 3):
        """
        äº¤å‰ç·¨ç¢¼å™¨é‡æ’åº

        å¯¦ä½œæ–¹å¼ï¼š
        1. ä½¿ç”¨å°ˆé–€çš„é‡æ’åºæ¨¡å‹
        2. ä½¿ç”¨ GPT è©•åˆ†
        3. ä½¿ç”¨ BERT é¢¨æ ¼æ¨¡å‹
        """
        # æ–¹æ³• 1ï¼šä½¿ç”¨ GPT è©•åˆ†
        reranked = []

        for doc in documents[:10]:  # é™åˆ¶æ•¸é‡æ§åˆ¶æˆæœ¬
            score = self._get_relevance_score_gpt(query, doc)
            reranked.append((doc, score))

        # æ–¹æ³• 2ï¼šä½¿ç”¨å°ˆé–€çš„é‡æ’åºæ¨¡å‹
        # from sentence_transformers import CrossEncoder
        # model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
        # pairs = [[query, doc] for doc in documents]
        # scores = model.predict(pairs)

        # æ’åº
        reranked.sort(key=lambda x: x[1], reverse=True)

        return reranked[:top_k]

    def _get_relevance_score_gpt(self, query: str, document: str) -> float:
        """
        ä½¿ç”¨ GPT è©•ä¼°ç›¸é—œæ€§

        å„ªé»ï¼šæº–ç¢ºåº¦é«˜
        ç¼ºé»ï¼šæˆæœ¬é«˜ã€é€Ÿåº¦æ…¢
        """
        prompt = f"""
        è©•ä¼°æ–‡æª”èˆ‡æŸ¥è©¢çš„ç›¸é—œæ€§ï¼ˆ0-10åˆ†ï¼‰ã€‚

        æŸ¥è©¢ï¼š{query}
        æ–‡æª”ï¼š{document[:500]}...

        åªè¿”å›æ•¸å­—åˆ†æ•¸ï¼š
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç›¸é—œæ€§è©•åˆ†å™¨"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=10
            )

            score = float(response.choices[0].message.content.strip())
            return score / 10.0
        except:
            return 0.5  # é è¨­åˆ†æ•¸
```

---

## ğŸ® ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
# 1. åˆå§‹åŒ–ç³»çµ±
rag = HybridRAGSystem(
    model="gpt-3.5-turbo",
    vector_weight=0.6,    # å‘é‡æ¬Šé‡
    keyword_weight=0.4    # é—œéµå­—æ¬Šé‡
)

# 2. æ·»åŠ çŸ¥è­˜
knowledge = """
FAISS æ˜¯ Facebook é–‹ç™¼çš„å‘é‡æª¢ç´¢åº«ã€‚
å®ƒæ”¯æ´åå„„ç´šå‘é‡çš„é«˜æ•ˆæª¢ç´¢ã€‚
å¸¸ç”¨çš„ç´¢å¼•é¡å‹åŒ…æ‹¬ Flatã€IVFã€HNSW ç­‰ã€‚
"""

rag.add_knowledge(knowledge, source="FAISSæ–‡æª”")

# 3. æŸ¥è©¢
question = "FAISS æ”¯æ´å¤šå¤§è¦æ¨¡çš„å‘é‡æª¢ç´¢ï¼Ÿ"
result = rag.answer_question(question)

print(f"ç­”æ¡ˆï¼š{result['answer']}")
print(f"ä¿¡å¿ƒåº¦ï¼š{result['confidence']:.2%}")
```

### é€²éšä½¿ç”¨

```python
# ä½¿ç”¨é‡æ’åº
result = rag.answer_question(
    question="å¦‚ä½•å„ªåŒ– FAISS æª¢ç´¢é€Ÿåº¦ï¼Ÿ",
    use_reranking=True,  # å•Ÿç”¨é‡æ’åº
    top_k=10  # åˆæ­¥æª¢ç´¢æ›´å¤šæ–‡æª”
)

# èª¿æ•´æª¢ç´¢åƒæ•¸
rag.vector_weight = 0.8  # å¢åŠ å‘é‡æ¬Šé‡ï¼ˆèªç¾©æœå°‹ï¼‰
rag.keyword_weight = 0.2  # é™ä½é—œéµå­—æ¬Šé‡

# æ‰¹é‡è™•ç†
questions = [
    "ä»€éº¼æ˜¯ BM25ï¼Ÿ",
    "FAISS å’Œ Annoy çš„å€åˆ¥ï¼Ÿ",
    "å¦‚ä½•é¸æ“‡åˆé©çš„ç´¢å¼•é¡å‹ï¼Ÿ"
]

results = []
for q in questions:
    result = rag.answer_question(q)
    results.append(result)
```

### ç³»çµ±è©•ä¼°

```python
def evaluate_system(rag_system, test_set):
    """
    è©•ä¼° RAG ç³»çµ±æ•ˆèƒ½
    """
    from sklearn.metrics import precision_recall_fscore_support

    predictions = []
    ground_truths = []

    for query, expected_docs, expected_answer in test_set:
        # æª¢ç´¢è©•ä¼°
        retrieved = rag_system.hybrid_search(query, top_k=5)
        retrieved_ids = [doc.id for doc, _, _ in retrieved]

        # è¨ˆç®—æª¢ç´¢æŒ‡æ¨™
        precision = len(set(retrieved_ids) & set(expected_docs)) / len(retrieved_ids)
        recall = len(set(retrieved_ids) & set(expected_docs)) / len(expected_docs)

        # ç”Ÿæˆè©•ä¼°
        result = rag_system.answer_question(query)

        # å¯ä»¥ä½¿ç”¨ ROUGEã€BLEU ç­‰æŒ‡æ¨™è©•ä¼°ç­”æ¡ˆå“è³ª

    return {
        "avg_precision": np.mean(precisions),
        "avg_recall": np.mean(recalls),
        "avg_f1": np.mean(f1_scores)
    }
```

---

## âš¡ æ•ˆèƒ½å„ªåŒ–

### 1. ç´¢å¼•å„ªåŒ–

```python
# é¸æ“‡åˆé©çš„ FAISS ç´¢å¼•
def choose_faiss_index(n_vectors, dimension, memory_limit_gb=8):
    """
    æ ¹æ“šè³‡æ–™è¦æ¨¡é¸æ“‡ç´¢å¼•
    """
    memory_per_vector = dimension * 4 / 1e9  # float32, GB
    total_memory = n_vectors * memory_per_vector

    if n_vectors < 50000:
        return "flat"  # å°è¦æ¨¡ï¼Œç²¾ç¢ºæœå°‹
    elif n_vectors < 1000000:
        if total_memory < memory_limit_gb:
            return "ivf"  # ä¸­è¦æ¨¡ï¼ŒIVF
        else:
            return "ivfpq"  # éœ€è¦å£“ç¸®
    else:
        return "hnsw"  # å¤§è¦æ¨¡ï¼Œåœ–ç´¢å¼•
```

### 2. æ‰¹è™•ç†å„ªåŒ–

```python
def batch_search(queries: List[str], batch_size: int = 32):
    """
    æ‰¹é‡æŸ¥è©¢å„ªåŒ–
    """
    results = []

    for i in range(0, len(queries), batch_size):
        batch = queries[i:i + batch_size]

        # æ‰¹é‡ç·¨ç¢¼
        embeddings = encode_batch(batch)

        # æ‰¹é‡æœå°‹
        batch_results = faiss_index.search_batch(embeddings)

        results.extend(batch_results)

    return results
```

### 3. å¿«å–ç­–ç•¥

```python
from functools import lru_cache
import hashlib

class CachedRetriever:
    def __init__(self, cache_size: int = 1000):
        self.cache_size = cache_size
        self.cache = {}

    def _get_cache_key(self, query: str) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        return hashlib.md5(query.encode()).hexdigest()

    @lru_cache(maxsize=1000)
    def search(self, query: str):
        """å¸¶å¿«å–çš„æœå°‹"""
        cache_key = self._get_cache_key(query)

        if cache_key in self.cache:
            return self.cache[cache_key]

        # åŸ·è¡Œå¯¦éš›æœå°‹
        result = self._actual_search(query)

        # æ›´æ–°å¿«å–
        self.cache[cache_key] = result

        return result
```

### 4. GPU åŠ é€Ÿ

```python
# ä½¿ç”¨ GPU ç‰ˆ FAISS
def setup_gpu_index(index, gpu_id=0):
    """
    å°‡ç´¢å¼•ç§»åˆ° GPU
    """
    import faiss

    # æª¢æŸ¥ GPU å¯ç”¨æ€§
    if not faiss.get_num_gpus():
        print("æ²’æœ‰å¯ç”¨çš„ GPU")
        return index

    # è¨­å®š GPU è³‡æº
    res = faiss.StandardGpuResources()

    # å°‡ç´¢å¼•ç§»åˆ° GPU
    gpu_index = faiss.index_cpu_to_gpu(res, gpu_id, index)

    return gpu_index
```

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•é¸æ“‡å‘é‡å’Œé—œéµå­—çš„æ¬Šé‡ï¼Ÿ

```python
def auto_tune_weights(validation_set):
    """
    è‡ªå‹•èª¿æ•´æ¬Šé‡
    """
    best_weights = None
    best_score = 0

    for vector_w in np.arange(0.3, 0.8, 0.1):
        keyword_w = 1 - vector_w

        # è©•ä¼°
        score = evaluate_with_weights(
            validation_set,
            vector_w,
            keyword_w
        )

        if score > best_score:
            best_score = score
            best_weights = (vector_w, keyword_w)

    return best_weights
```

### Q2: è™•ç†é•·æ–‡æª”çš„ç­–ç•¥ï¼Ÿ

```python
def handle_long_document(doc, max_length=1000):
    """
    é•·æ–‡æª”è™•ç†ç­–ç•¥
    """
    if len(doc) <= max_length:
        return [doc]

    # ç­–ç•¥ 1ï¼šæ»‘å‹•è¦–çª—
    chunks = []
    window_size = 500
    stride = 250

    for i in range(0, len(doc), stride):
        chunk = doc[i:i + window_size]
        chunks.append(chunk)

    # ç­–ç•¥ 2ï¼šé‡è¦æ®µè½æå–
    # important_parts = extract_important_sections(doc)

    return chunks
```

### Q3: å¦‚ä½•è™•ç†å¤šèªè¨€æŸ¥è©¢ï¼Ÿ

```python
class MultilingualProcessor:
    """
    å¤šèªè¨€è™•ç†å™¨
    """
    def detect_language(self, text):
        """èªè¨€æª¢æ¸¬"""
        from langdetect import detect
        return detect(text)

    def process(self, text):
        """æ ¹æ“šèªè¨€é¸æ“‡è™•ç†æ–¹å¼"""
        lang = self.detect_language(text)

        if lang == 'zh':
            return self.process_chinese(text)
        elif lang == 'en':
            return self.process_english(text)
        else:
            return self.process_mixed(text)
```

### Q4: å¦‚ä½•ç›£æ§ç³»çµ±æ•ˆèƒ½ï¼Ÿ

```python
class PerformanceMonitor:
    """
    æ•ˆèƒ½ç›£æ§å™¨
    """
    def __init__(self):
        self.metrics = {
            'query_count': 0,
            'avg_latency': 0,
            'cache_hit_rate': 0,
            'retrieval_accuracy': []
        }

    def log_query(self, query, latency, cache_hit=False):
        """è¨˜éŒ„æŸ¥è©¢"""
        self.metrics['query_count'] += 1
        self.metrics['avg_latency'] = (
            self.metrics['avg_latency'] * (self.metrics['query_count'] - 1) +
            latency
        ) / self.metrics['query_count']

        if cache_hit:
            self.metrics['cache_hit_rate'] += 1

    def get_report(self):
        """ç”Ÿæˆå ±å‘Š"""
        return {
            'ç¸½æŸ¥è©¢æ•¸': self.metrics['query_count'],
            'å¹³å‡å»¶é²': f"{self.metrics['avg_latency']:.2f}ç§’",
            'å¿«å–å‘½ä¸­ç‡': f"{self.metrics['cache_hit_rate'] / self.metrics['query_count']:.2%}",
        }
```

---

## ğŸ“Š æ•ˆèƒ½åŸºæº–æ¸¬è©¦

### æ¸¬è©¦ç’°å¢ƒ

```
CPU: Intel i7-10700K
RAM: 32GB
GPU: NVIDIA RTX 3070 (å¯é¸)
Python: 3.9
```

### æ¸¬è©¦çµæœ

| æ–‡æª”æ•¸é‡ | ç´¢å¼•é¡å‹ | å»ºç«‹æ™‚é–“ | æŸ¥è©¢æ™‚é–“ | è¨˜æ†¶é«”ä½¿ç”¨ |
|---------|---------|---------|---------|-----------|
| 10K | Flat | 2s | 5ms | 150MB |
| 100K | IVF | 30s | 10ms | 1.5GB |
| 1M | HNSW | 5min | 2ms | 8GB |
| 10M | IVF+PQ | 30min | 20ms | 3GB |

### æª¢ç´¢å“è³ªå°æ¯”

| æ–¹æ³• | Precision@5 | Recall@5 | F1 Score |
|------|------------|----------|----------|
| ç´”å‘é‡ | 0.72 | 0.68 | 0.70 |
| ç´” BM25 | 0.65 | 0.75 | 0.70 |
| **æ··åˆæª¢ç´¢** | **0.82** | **0.78** | **0.80** |
| æ··åˆ+é‡æ’åº | 0.88 | 0.76 | 0.82 |

---

## ğŸ¯ ç¸½çµ

### æ··åˆæª¢ç´¢ RAG çš„å„ªå‹¢

1. **æ›´é«˜çš„å¬å›ç‡**ï¼šçµåˆèªç¾©å’Œé—œéµå­—åŒ¹é…
2. **æ›´å¥½çš„æ’åº**ï¼šå¤šç¶­åº¦è©•åˆ†èåˆ
3. **é©æ‡‰æ€§å¼·**ï¼šè‡ªå‹•å¹³è¡¡ä¸åŒæŸ¥è©¢é¡å‹
4. **å¯è§£é‡‹æ€§**ï¼šä¿ç•™é—œéµå­—åŒ¹é…çš„é€æ˜åº¦

### æœ€ä½³å¯¦è¸

1. **æ ¹æ“šè³‡æ–™è¦æ¨¡é¸æ“‡ç´¢å¼•**
2. **å‹•æ…‹èª¿æ•´æª¢ç´¢æ¬Šé‡**
3. **ä½¿ç”¨å¿«å–åŠ é€Ÿå¸¸è¦‹æŸ¥è©¢**
4. **å®šæœŸè©•ä¼°å’Œå„ªåŒ–**

### æœªä¾†å±•æœ›

- ç¥ç¶“æª¢ç´¢æ¨¡å‹ï¼ˆNeural IRï¼‰
- å­¸ç¿’æ’åºï¼ˆLearning to Rankï¼‰
- åœ–ç¥ç¶“ç¶²è·¯æª¢ç´¢
- å¤šæ¨¡æ…‹æª¢ç´¢ï¼ˆæ–‡å­—+åœ–åƒï¼‰

---

**ç¥æ‚¨å»ºç«‹å‡ºé«˜æ•ˆçš„æ··åˆæª¢ç´¢ RAG ç³»çµ±ï¼** ğŸš€

å¦‚æœ‰ä»»ä½•å•é¡Œï¼Œæ­¡è¿éš¨æ™‚è¨è«–äº¤æµã€‚