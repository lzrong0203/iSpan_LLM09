# Day 2 ä¸‹åˆï¼šå¾®èª¿ç¤ºç¯„
# 14:30-15:30 LoRAå¾®èª¿æ¦‚å¿µ

import json
import os
from typing import Dict, List

# === Step 1: ä»€éº¼æ˜¯å¾®èª¿ï¼Ÿ ===
print("=== å¾®èª¿ (Fine-tuning) æ¦‚å¿µ ===")
print()
print("å¾®èª¿ = è®“AIå­¸ç¿’ä½ çš„é¢¨æ ¼")
print()
print("æƒ³åƒæˆï¼š")
print("ğŸ¨ åŸå§‹æ¨¡å‹ = æœƒç•«ç•«çš„è—è¡“å®¶")
print("ğŸ–Œï¸ å¾®èª¿ = æ•™ä»–ä½ çš„ç•«é¢¨")
print("ğŸ–¼ï¸ çµæœ = ç”¨ä½ çš„é¢¨æ ¼ä½œç•«")
print()

# === Step 2: ä»€éº¼æ˜¯LoRAï¼Ÿ ===
print("=== LoRAæŠ€è¡“ ===")
print()
print("LoRA = Low-Rank Adaptation")
print()
print("å‚³çµ±å¾®èª¿ vs LoRAï¼š")
print("âŒ å‚³çµ±ï¼šèª¿æ•´100%åƒæ•¸ï¼ˆå¾ˆæ…¢ã€å¾ˆè²´ï¼‰")
print("âœ… LoRAï¼šåªèª¿æ•´1-5%åƒæ•¸ï¼ˆå¿«é€Ÿã€ä¾¿å®œï¼‰")
print()
print("å°±åƒï¼š")
print("å‚³çµ± = é‡æ–°è£ä¿®æ•´é–“æˆ¿å­")
print("LoRA = åªæ›çª—ç°¾å’Œå®¶å…·")
print()


# === Step 3: æº–å‚™è¨“ç·´è³‡æ–™ ===
class DatasetPreparer:
    """è¨“ç·´è³‡æ–™æº–å‚™å™¨"""

    def __init__(self):
        self.training_data = []

    def add_example(self, instruction: str, input_text: str, output: str):
        """æ·»åŠ è¨“ç·´ç¯„ä¾‹"""
        self.training_data.append(
            {"instruction": instruction, "input": input_text, "output": output}
        )

    def prepare_ptt_style_data(self):
        """æº–å‚™PTTé¢¨æ ¼è³‡æ–™"""
        print("æº–å‚™PTTé„‰æ°‘é¢¨æ ¼è³‡æ–™...")

        # å¾ ptt_gossiping_dataset_100.json è¼‰å…¥è³‡æ–™
        dataset_path = "/home/lzrong/iSpan/LLM09/ptt_gossiping_dataset_100.json"

        try:
            with open(dataset_path, "r", encoding="utf-8") as f:
                # é€è¡Œè®€å– JSON è³‡æ–™
                lines = f.readlines()
                ptt_examples = []

                for line in lines[:10]:  # ä½¿ç”¨å‰10ç­†è³‡æ–™ä½œç‚ºç¯„ä¾‹
                    data = json.loads(line.strip())
                    text = data["text"]

                    # è§£ææ ¼å¼åŒ–çš„æ–‡å­—
                    # æ ¼å¼ï¼š[INST] æŒ‡ä»¤ï¼š... å•é¡Œï¼š... [/INST] å›ç­”
                    if "[INST]" in text and "[/INST]" in text:
                        parts = text.split("[/INST]")
                        instruction_part = parts[0].replace("[INST]", "").strip()
                        output = parts[1].replace("</s>", "").replace("<s>", "").strip()

                        # æå–å•é¡Œ
                        if "å•é¡Œï¼š" in instruction_part:
                            input_text = instruction_part.split("å•é¡Œï¼š")[1].strip()
                        else:
                            input_text = instruction_part

                        ptt_examples.append({
                            "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                            "input": input_text,
                            "output": output
                        })

                # å¦‚æœç„¡æ³•è¼‰å…¥å¤–éƒ¨è³‡æ–™ï¼Œä½¿ç”¨é è¨­ç¯„ä¾‹
                if not ptt_examples:
                    raise Exception("ç„¡æ³•è§£æè³‡æ–™")

        except Exception as e:
            print(f"è¼‰å…¥å¤–éƒ¨è³‡æ–™å¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­ç¯„ä¾‹")
            # é è¨­ç¯„ä¾‹ä½œç‚ºå‚™ç”¨
            ptt_examples = [
                {
                    "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                    "input": "æœ€è¿‘è‚¡å¸‚æœƒæ¼²å—ï¼Ÿ",
                    "output": "all inå°±å°äº†å•¦ï¼Œè¼¸äº†å†ä¾†ç™¼æ–‡å–æš–ï¼Œå˜»å˜»",
                },
                {
                    "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                    "input": "è©²è²·æˆ¿é‚„æ˜¯ç§Ÿæˆ¿ï¼Ÿ",
                    "output": "è²·ä¸èµ·å•¦QQï¼Œç¹¼çºŒç•¶ç¤¾ç•œå­˜é ­æœŸæ¬¾ï¼Œå”‰",
                },
                {
                    "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                    "input": "å·¥ä½œå£“åŠ›å¥½å¤§æ€éº¼è¾¦ï¼Ÿ",
                    "output": "å…ˆæ¨æ–‡å†èªªï¼Œä¸‹ç­è²·é¹¹é…¥é›å£“å£“é©šï¼Œçµ¦ä½ æ‹æ‹",
                },
                {
                    "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                    "input": "è¦æ€éº¼è„«å–®ï¼Ÿ",
                    "output": "å…ˆæ¸›è‚¥å•¦ï¼Œç„¶å¾Œè¨˜å¾—æ´—æ¾¡ï¼ŒèªçœŸå›",
                },
                {
                    "instruction": "ç”¨PTTé„‰æ°‘çš„èªæ°£å›ç­”",
                    "input": "æ¨è–¦ä»€éº¼ç¾é£Ÿï¼Ÿ",
                    "output": "å··å£æ»·è‚‰é£¯ï¼Œä¾¿å®œåˆå¤§ç¢—ï¼ŒçœŸé¦™",
                },
            ]

        for example in ptt_examples:
            self.add_example(
                example["instruction"], example["input"], example["output"]
            )

        print(f"æº–å‚™äº† {len(ptt_examples)} å€‹PTTé¢¨æ ¼ç¯„ä¾‹")

    def prepare_professional_data(self):
        """æº–å‚™å°ˆæ¥­é¢¨æ ¼è³‡æ–™"""
        print("æº–å‚™å°ˆæ¥­å®¢æœé¢¨æ ¼è³‡æ–™...")

        professional_examples = [
            {
                "instruction": "ç”¨å°ˆæ¥­å®¢æœçš„èªæ°£å›ç­”",
                "input": "ç”¢å“æœ‰å•é¡Œ",
                "output": "éå¸¸æŠ±æ­‰çµ¦æ‚¨å¸¶ä¾†ä¸ä¾¿ï¼Œæˆ‘å€‘æœƒç«‹å³ç‚ºæ‚¨è™•ç†ã€‚è«‹æä¾›è¨‚å–®ç·¨è™Ÿï¼Œæˆ‘å€‘å°‡å„ªå…ˆè™•ç†æ‚¨çš„æ¡ˆä»¶ã€‚",
            },
            {
                "instruction": "ç”¨å°ˆæ¥­å®¢æœçš„èªæ°£å›ç­”",
                "input": "è¦é€€è²¨",
                "output": "äº†è§£æ‚¨çš„éœ€æ±‚ã€‚æ ¹æ“šæˆ‘å€‘çš„é€€è²¨æ”¿ç­–ï¼Œæ‚¨å¯ä»¥åœ¨æ”¶åˆ°å•†å“å¾Œ7å¤©å…§ç”³è«‹é€€è²¨ã€‚è«‹å•æ˜¯å¦æ–¹ä¾¿å‘ŠçŸ¥é€€è²¨åŸå› ï¼Ÿ",
            },
            {
                "instruction": "ç”¨å°ˆæ¥­å®¢æœçš„èªæ°£å›ç­”",
                "input": "å¤šä¹…åˆ°è²¨ï¼Ÿ",
                "output": "æ„Ÿè¬æ‚¨çš„è©¢å•ã€‚ä¸€èˆ¬æƒ…æ³ä¸‹ï¼Œè¨‚å–®æœƒåœ¨1-3å€‹å·¥ä½œæ—¥å…§é€é”ã€‚æ‚¨å¯ä»¥é€éè¨‚å–®è¿½è¹¤ç³»çµ±æŸ¥çœ‹å³æ™‚ç‹€æ…‹ã€‚",
            },
        ]

        for example in professional_examples:
            self.add_example(
                example["instruction"], example["input"], example["output"]
            )

        print(f"æº–å‚™äº† {len(professional_examples)} å€‹å°ˆæ¥­é¢¨æ ¼ç¯„ä¾‹")

    def save_dataset(self, filename: str):
        """å„²å­˜è³‡æ–™é›†"""
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(self.training_data, f, ensure_ascii=False, indent=2)
        print(f"è³‡æ–™é›†å·²å„²å­˜åˆ° {filename}")
        print(f"å…± {len(self.training_data)} å€‹è¨“ç·´ç¯„ä¾‹")

    def load_dataset(self, filename: str):
        """è¼‰å…¥è³‡æ–™é›†"""
        with open(filename, "r", encoding="utf-8") as f:
            self.training_data = json.load(f)
        print(f"å¾ {filename} è¼‰å…¥äº† {len(self.training_data)} å€‹ç¯„ä¾‹")


# === Step 4: è³‡æ–™é›†æ ¼å¼åŒ– ===
def format_for_training(data: List[Dict]) -> List[str]:
    """æ ¼å¼åŒ–æˆè¨“ç·´æ ¼å¼"""
    formatted = []

    for item in data:
        # Alpacaæ ¼å¼
        prompt = f"""### Instruction:
{item['instruction']}

### Input:
{item['input']}

### Response:
{item['output']}"""
        formatted.append(prompt)

    return formatted


# === Step 5: æ¨¡æ“¬å¾®èª¿éç¨‹ ===
class LoRATrainer:
    """LoRAè¨“ç·´å™¨ï¼ˆæ¨¡æ“¬ï¼‰"""

    def __init__(self, base_model: str = "llama2"):
        self.base_model = base_model
        self.lora_weights = None
        self.training_history = []

    def train(self, dataset: List[Dict], epochs: int = 3):
        """æ¨¡æ“¬è¨“ç·´éç¨‹"""
        print(f"\n=== é–‹å§‹LoRAè¨“ç·´ ===")
        print(f"åŸºç¤æ¨¡å‹ï¼š{self.base_model}")
        print(f"è¨“ç·´æ¨£æœ¬ï¼š{len(dataset)}")
        print(f"è¨“ç·´è¼ªæ•¸ï¼š{epochs}")
        print()

        for epoch in range(epochs):
            print(f"Epoch {epoch+1}/{epochs}")

            # æ¨¡æ“¬è¨“ç·´é€²åº¦
            for i in range(0, 101, 20):
                print(f"  é€²åº¦ï¼š{'â–ˆ' * (i//5)}{'â–‘' * (20-i//5)} {i}%", end="\r")
                import time

                time.sleep(0.2)

            # æ¨¡æ“¬æå¤±ä¸‹é™
            loss = 2.0 / (epoch + 1)
            self.training_history.append({"epoch": epoch + 1, "loss": loss})

            print(f"  é€²åº¦ï¼š{'â–ˆ' * 20} 100%")
            print(f"  Loss: {loss:.4f}")
            print()

        print("âœ… è¨“ç·´å®Œæˆï¼")
        self.lora_weights = "lora_weights.bin"  # æ¨¡æ“¬æ¬Šé‡æª”æ¡ˆ

    def save_adapter(self, path: str):
        """å„²å­˜LoRAé©é…å™¨"""
        print(f"å„²å­˜LoRAé©é…å™¨åˆ° {path}")
        # å¯¦éš›æ‡‰ç”¨ä¸­æœƒå„²å­˜æ¬Šé‡æª”æ¡ˆ
        with open(f"{path}/adapter_config.json", "w") as f:
            json.dump(
                {
                    "base_model": self.base_model,
                    "lora_rank": 8,
                    "lora_alpha": 16,
                    "target_modules": ["q_proj", "v_proj"],
                },
                f,
                indent=2,
            )
        print("âœ… é©é…å™¨å·²å„²å­˜")


# === Step 6: æ¸¬è©¦å¾®èª¿æ•ˆæœ ===
class FineTunedModel:
    """å¾®èª¿å¾Œçš„æ¨¡å‹ï¼ˆæ¨¡æ“¬ï¼‰"""

    def __init__(self, base_model: str, lora_adapter: str = None):
        self.base_model = base_model
        self.lora_adapter = lora_adapter
        self.style = None

        if lora_adapter:
            # è¼‰å…¥LoRAé¢¨æ ¼
            if "ptt" in lora_adapter.lower():
                self.style = "ptt"
            elif "professional" in lora_adapter.lower():
                self.style = "professional"

    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆå›æ‡‰"""
        if self.style == "ptt":
            # PTTé¢¨æ ¼å›æ‡‰
            responses = {
                "è‚¡ç¥¨": "åˆ¥å•ï¼Œå•å°±æ˜¯all inå°ç©é›»",
                "ç¾é£Ÿ": "å··å£é‚£å®¶çœŸçš„è®šï¼Œåƒäº†æœƒä¸Šç™®",
                "å·¥ä½œ": "æ…£è€é—†ä¸æ„å¤–ï¼Œæ‹æ‹",
                "æ„Ÿæƒ…": "å…ˆå»å¥èº«æˆ¿å•¦ï¼ŒèªçœŸå»ºè­°",
            }

            for key, response in responses.items():
                if key in prompt:
                    return response
            return "æ¨æ–‡å…ˆï¼Œç­‰ç­‰å†ä¾†èªçœŸå›"

        elif self.style == "professional":
            # å°ˆæ¥­é¢¨æ ¼å›æ‡‰
            return f"æ„Ÿè¬æ‚¨çš„è©¢å•ã€‚é—œæ–¼ã€Œ{prompt}ã€ï¼Œæˆ‘å€‘æœƒç›¡å¿«ç‚ºæ‚¨æä¾›å”åŠ©ã€‚"
        else:
            # åŸå§‹æ¨¡å‹å›æ‡‰
            return f"é€™æ˜¯å°ã€Œ{prompt}ã€çš„ä¸€èˆ¬å›æ‡‰ã€‚"


# === Step 7: åŸ·è¡Œç¤ºç¯„ ===
print("=== å¾®èª¿ç¤ºç¯„ ===")
print()

# æº–å‚™è³‡æ–™
preparer = DatasetPreparer()

print("é¸æ“‡è¨“ç·´é¢¨æ ¼ï¼š")
print("1. PTTé„‰æ°‘é¢¨æ ¼")
print("2. å°ˆæ¥­å®¢æœé¢¨æ ¼")
print("3. å…©ç¨®éƒ½è¦")
print()

choice = input("é¸æ“‡ (1-3)ï¼š")

if choice == "1":
    preparer.prepare_ptt_style_data()
    dataset_name = "ptt_dataset.json"
elif choice == "2":
    preparer.prepare_professional_data()
    dataset_name = "professional_dataset.json"
else:
    preparer.prepare_ptt_style_data()
    preparer.prepare_professional_data()
    dataset_name = "mixed_dataset.json"

# å„²å­˜è³‡æ–™é›†
preparer.save_dataset(dataset_name)

# æ ¼å¼åŒ–è³‡æ–™
formatted_data = format_for_training(preparer.training_data)
print(f"\næ ¼å¼åŒ–å¾Œçš„ç¬¬ä¸€å€‹ç¯„ä¾‹ï¼š")
print(formatted_data[0])
print()

# è¨“ç·´æ¨¡å‹
trainer = LoRATrainer()
trainer.train(preparer.training_data, epochs=3)

# å„²å­˜é©é…å™¨
os.makedirs("lora_adapter", exist_ok=True)
trainer.save_adapter("lora_adapter")

# === Step 8: æ¸¬è©¦å¾®èª¿æ•ˆæœ ===
print("\n=== æ¸¬è©¦å¾®èª¿æ•ˆæœ ===")
print()

# åŸå§‹æ¨¡å‹
original_model = FineTunedModel("llama2")

# å¾®èª¿å¾Œæ¨¡å‹
if "ptt" in dataset_name:
    finetuned_model = FineTunedModel("llama2", "ptt_lora")
else:
    finetuned_model = FineTunedModel("llama2", "professional_lora")

# æ¸¬è©¦å•é¡Œ
test_prompts = ["æœ€è¿‘è‚¡ç¥¨æ€éº¼æ¨£ï¼Ÿ", "æ¨è–¦å¥½åƒçš„ç¾é£Ÿ", "å·¥ä½œå£“åŠ›å¾ˆå¤§"]

for prompt in test_prompts:
    print(f"å•é¡Œï¼š{prompt}")
    print(f"åŸå§‹æ¨¡å‹ï¼š{original_model.generate(prompt)}")
    print(f"å¾®èª¿æ¨¡å‹ï¼š{finetuned_model.generate(prompt)}")
    print()

# === Step 9: å¾®èª¿å»ºè­° ===
print("=" * 50)
print("=== å¾®èª¿å¯¦å‹™å»ºè­° ===")
print()

tips = [
    "ğŸ“Š è³‡æ–™å“è³ª > è³‡æ–™æ•¸é‡",
    "ğŸ¯ å°ˆæ³¨ç‰¹å®šä»»å‹™æ•ˆæœæ›´å¥½",
    "âš¡ LoRAåªéœ€è¦æ¶ˆè²»ç´šGPU",
    "ğŸ’¾ LoRAæª”æ¡ˆé€šå¸¸åªæœ‰å¹¾åMB",
    "ğŸ”„ å¯ä»¥åˆ‡æ›ä¸åŒçš„LoRAé¢¨æ ¼",
    "ğŸ§ª å»ºè­°å¾å°è³‡æ–™é›†é–‹å§‹å¯¦é©—",
]

for tip in tips:
    print(tip)

print()
print("ğŸ’¡ å¾®èª¿è®“AIè®Šæˆä½ çš„å°ˆå±¬åŠ©æ‰‹ï¼")
