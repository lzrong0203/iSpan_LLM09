# 🎨 LLM 核心概念視覺化解說

## 目錄
- [Transformer 架構圖解](#transformer-架構圖解)
- [Attention 機制動畫說明](#attention-機制動畫說明)
- [Token 化過程視覺化](#token-化過程視覺化)
- [RAG 工作流程圖](#rag-工作流程圖)
- [Fine-tuning vs LoRA 比較](#fine-tuning-vs-lora-比較)

---

## Transformer 架構圖解

### 整體架構（簡化版）

```
                    🎯 輸出文字
                         ↑
                    ┌─────────┐
                    │ 解碼器  │
                    │ Output  │
                    └─────────┘
                         ↑
                ┌────────────────┐
                │                │
                │  Transformer   │
                │     Block      │
                │                │
                │ [Self-Attention]│
                │       +         │
                │ [Feed Forward]  │
                │       +         │
                │ [Layer Norm]    │
                └────────────────┘
                         ↑
                    ┌─────────┐
                    │ 嵌入層  │
                    │Embedding│
                    └─────────┘
                         ↑
                    📝 輸入文字
```

### 詳細資料流動

```
輸入: "我愛吃蘋果"
        ↓
[步驟1: Tokenization]
["我", "愛", "吃", "蘋果"]
        ↓
[步驟2: Embedding]
[[0.2, 0.5, ...],   # "我" 的向量
 [0.1, 0.8, ...],   # "愛" 的向量
 [0.3, 0.4, ...],   # "吃" 的向量  
 [0.6, 0.2, ...]]   # "蘋果" 的向量
        ↓
[步驟3: Position Encoding]
加入位置資訊
        ↓
[步驟4: Multi-Head Attention]
每個詞關注其他詞
        ↓
[步驟5: Feed Forward]
深層特徵提取
        ↓
[步驟6: 輸出層]
預測下一個詞
```

---

## Attention 機制動畫說明

### 1. Self-Attention 運作過程

```
句子: "小明 喜歡 吃 蘋果"

Step 1: 計算注意力分數
═══════════════════════════════════════════

當處理 "蘋果" 這個詞時：

        小明   喜歡   吃   蘋果
蘋果 →  0.1   0.2   0.6   0.1   (注意力分數)
        ↓     ↓     ↓     ↓
        💤    🙂    😍    💤
      (低)   (中)  (高)  (自己)

解釋: "蘋果" 最關注 "吃" 這個動作詞
```

### 2. Multi-Head Attention 

```
同時從多個角度理解句子：

Head 1: 語法關係
╔════════════════╗
║ 小明 → 喜歡    ║ (主語-動詞)
║ 喜歡 → 吃      ║ (動詞串連)
║ 吃 → 蘋果      ║ (動詞-賓語)
╚════════════════╝

Head 2: 語意關係
╔════════════════╗
║ 小明 ← → 喜歡  ║ (人物-情感)
║ 吃 ← → 蘋果    ║ (動作-對象)
╚════════════════╝

Head 3: 位置關係
╔════════════════╗
║ 相鄰詞彙關聯   ║
║ 遠距詞彙關聯   ║
╚════════════════╝

最終輸出 = 綜合所有 Head 的理解
```

### 3. 注意力矩陣視覺化

```
    我  愛  吃  蘋  果
    ─────────────────
我  ■■  ■□  □□  □□  □□
愛  ■□  ■■  ■□  □□  □□  
吃  □□  ■□  ■■  ■■  ■□
蘋  □□  □□  ■■  ■■  ■□
果  □□  □□  ■□  ■□  ■■

■■ = 強關聯 (0.7-1.0)
■□ = 中關聯 (0.3-0.7)
□□ = 弱關聯 (0.0-0.3)
```

---

## Token 化過程視覺化

### 英文 Tokenization

```
原始文字: "Hello World! How are you?"
                    ↓
Step 1: 基本分割
["Hello", " ", "World", "!", " ", "How", " ", "are", " ", "you", "?"]
                    ↓
Step 2: 子詞分割 (Subword)
["Hello", " World", "!", " How", " are", " you", "?"]
                    ↓
Step 3: Token ID 映射
[15496, 2159, 999, 1374, 389, 345, 30]
                    ↓
Step 4: 特殊標記
[<BOS>, 15496, 2159, 999, 1374, 389, 345, 30, <EOS>]
```

### 中文 Tokenization

```
原始文字: "我愛自然語言處理"
                    ↓
方法 1: 字元級別
["我", "愛", "自", "然", "語", "言", "處", "理"]
Token IDs: [2769, 3859, 5632, 4197, 6427, 8000, 5662, 3972]

方法 2: 詞級別
["我", "愛", "自然", "語言", "處理"]  
Token IDs: [2769, 3859, 45632, 16427, 35662]

方法 3: BPE (Byte-Pair Encoding)
["我", "愛", "自然", "語言處", "理"]
Token IDs: [2769, 3859, 45632, 164275, 3972]
```

### Token 長度影響

```
相同意思，不同語言的 Token 數量：

英文: "I love you" → 3 tokens
中文: "我愛你" → 3 tokens
日文: "愛してる" → 4 tokens
韓文: "사랑해" → 5 tokens

💡 Token 數量影響：
- API 成本（按 token 計費）
- 處理速度（token 越多越慢）
- 上下文長度限制
```

---

## RAG 工作流程圖

### 完整 RAG 系統流程

```
┌─────────────────────────────────────────────┐
│              使用者查詢                      │
│         "Python 是誰發明的？"                │
└────────────────┬────────────────────────────┘
                 ↓
        ┌─────────────────┐
        │   查詢編碼器    │
        │  Query Encoder  │
        └────────┬────────┘
                 ↓
            查詢向量
         [0.2, 0.5, ...]
                 ↓
┌──────────────────────────────────────┐
│          向量資料庫                  │
│  ┌─────┐  ┌─────┐  ┌─────┐         │
│  │Doc1 │  │Doc2 │  │Doc3 │  ...    │
│  │vec1 │  │vec2 │  │vec3 │         │
│  └─────┘  └─────┘  └─────┘         │
└──────────────┬───────────────────────┘
               ↓
         相似度計算
               ↓
    ┌───────────────────┐
    │   Top-K 文檔      │
    │ 1. Python 簡介    │
    │ 2. Guido 傳記     │
    │ 3. 程式語言歷史   │
    └─────────┬─────────┘
              ↓
    ┌─────────────────────┐
    │    上下文組合        │
    │  Context + Query     │
    └──────────┬──────────┘
               ↓
    ┌─────────────────────┐
    │       LLM 生成       │
    │   Generate Answer    │
    └──────────┬──────────┘
               ↓
    ┌─────────────────────────────┐
    │          最終答案            │
    │ "Python 是由 Guido van      │
    │  Rossum 在 1991 年發明的"   │
    └─────────────────────────────┘
```

### RAG vs 純 LLM 比較

```
純 LLM 回答流程:
問題 → LLM → 答案
      (依賴訓練時的知識)

RAG 回答流程:
問題 → 搜尋 → 相關文檔 → LLM → 答案
              (即時知識)    (結合生成)

優勢對比:
┌────────────┬────────────┬────────────┐
│    特性    │   純 LLM   │    RAG     │
├────────────┼────────────┼────────────┤
│ 知識更新   │    困難    │    簡單    │
│ 準確性     │    一般    │     高     │
│ 可追溯性   │     無     │     有     │
│ 成本       │     低     │    較高    │
└────────────┴────────────┴────────────┘
```

---

## Fine-tuning vs LoRA 比較

### 傳統 Fine-tuning

```
原始模型 (7B 參數)
    ↓
[====================] 100% 參數都要更新
    ↓
微調後模型 (7B 新參數)

📊 特點:
• 需要儲存完整的 7B 參數
• 訓練時需要大量 GPU 記憶體
• 效果好但成本高
```

### LoRA (低秩適應)

```
原始模型 (7B 參數)
    ↓
[====================] 凍結 99%
    +
[▪▪] 只訓練 1% (LoRA 層)
    ↓
原始模型 + LoRA 適配器 (7B + 10MB)

📊 特點:
• 只需儲存小的 LoRA 權重
• 可以切換不同的 LoRA
• 訓練快速且省資源
```

### 視覺化比較

```
場景：訓練模型成為不同專家

傳統 Fine-tuning:
┌──────────┐      ┌──────────┐      ┌──────────┐
│ 基礎模型 │ →→→  │ 醫療專家 │      │ 法律專家 │
│   7GB    │      │   7GB    │      │   7GB    │
└──────────┘      └──────────┘      └──────────┘
                  需要 14GB 儲存空間

LoRA 方法:
┌──────────┐      ┌─────┐    ┌─────┐
│ 基礎模型 │  +   │醫療 │ or │法律 │
│   7GB    │      │10MB │    │10MB │
└──────────┘      └─────┘    └─────┘
                  只需 7.02GB 儲存空間
```

### 數學原理（簡化說明）

```
原始權重矩陣 W (大)
    ↓
分解成兩個小矩陣
    ↓
W = W₀ + BA
    
其中:
• W₀: 原始凍結權重 (不變)
• B: 下投影矩陣 (d × r)
• A: 上投影矩陣 (r × d)
• r << d (r 遠小於 d)

範例:
原始: 1024 × 1024 = 1,048,576 參數
LoRA: (1024 × 8) + (8 × 1024) = 16,384 參數
節省: 98.4% 🎉
```

---

## Prompt Engineering 視覺化

### Prompt 結構拆解

```
完整 Prompt 結構:
┌────────────────────────────────┐
│         System Prompt          │ ← 角色設定
├────────────────────────────────┤
│         Context/Examples       │ ← 背景資訊
├────────────────────────────────┤
│         User Query             │ ← 實際問題
├────────────────────────────────┤
│         Output Format          │ ← 格式要求
└────────────────────────────────┘

範例:
┌────────────────────────────────┐
│ "你是一位專業的程式講師"       │
├────────────────────────────────┤
│ "以下是 Python 的基本語法..."  │
├────────────────────────────────┤
│ "請解釋什麼是變數"             │
├────────────────────────────────┤
│ "用初學者能懂的方式，200字內"  │
└────────────────────────────────┘
```

### Few-shot Learning 示意

```
Zero-shot (無範例):
輸入: "翻譯: Hello"
輸出: ???

One-shot (一個範例):
輸入: "Dog → 狗
      Cat → ?"
輸出: "貓"

Few-shot (多個範例):
輸入: "Dog → 狗
      Cat → 貓
      Bird → 鳥
      Fish → ?"
輸出: "魚"

效果比較:
Zero-shot  ████░░░░░░ 40%
One-shot   ███████░░░ 70%
Few-shot   █████████░ 90%
```

---

## 模型大小與效能關係

```
模型參數量對比:
                                        
GPT-2    ▓░░░░░░░░░  1.5B
GPT-3    ▓▓▓▓▓▓▓▓▓▓  175B
Llama-7B ▓▓▓░░░░░░░  7B
Llama-13B ▓▓▓▓▓░░░░  13B
Llama-70B ▓▓▓▓▓▓▓▓░  70B
GPT-4    ▓▓▓▓▓▓▓▓▓▓  ~1.8T (推測)

資源需求 vs 效能:
┌──────────┬───────┬────────┬────────┐
│  模型     │ VRAM  │ 速度   │ 品質   │
├──────────┼───────┼────────┼────────┤
│ 3B       │  6GB  │ 快 ⚡⚡⚡ │ ★★☆☆☆ │
│ 7B       │ 14GB  │ 中 ⚡⚡   │ ★★★☆☆ │
│ 13B      │ 26GB  │ 慢 ⚡    │ ★★★★☆ │
│ 70B      │140GB  │ 很慢    │ ★★★★★ │
└──────────┴───────┴────────┴────────┘
```

---

## 訓練過程視覺化

```
訓練循環:

     ┌─────────────┐
     │  輸入資料   │
     └──────┬──────┘
            ↓
     ┌─────────────┐
     │  前向傳播   │ → 預測輸出
     └──────┬──────┘
            ↓
     ┌─────────────┐
     │  計算損失   │ ← 比較答案
     └──────┬──────┘
            ↓
     ┌─────────────┐
     │  反向傳播   │ → 計算梯度
     └──────┬──────┘
            ↓
     ┌─────────────┐
     │  更新權重   │
     └──────┬──────┘
            ↓
        [重複循環]

訓練進度:
Epoch 1: ████░░░░░░ 40% Loss: 2.5
Epoch 2: ███████░░░ 70% Loss: 1.2
Epoch 3: ██████████ 100% Loss: 0.3
```

---

## 💡 視覺化小結

這些圖表幫助理解：

1. **架構層面**：Transformer 如何處理資訊
2. **機制層面**：Attention 如何運作
3. **實作層面**：Token、RAG、微調的具體流程
4. **應用層面**：如何選擇和使用不同技術

記住：
- 圖表是簡化的模型，實際更複雜
- 重點是理解概念，不是記住細節
- 實作時可以參考這些流程圖

需要更詳細的解釋，隨時提問！ 🚀